# -*- coding: utf-8 -*-
"""churn_rf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iQHz1PYmCep2d-iJLF_P88L2h6tgoNAT
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.ticker as mtick
import matplotlib.pyplot as plt
# %matplotlib inline

df=pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")

df.head()

df.describe()

df.shape

df.columns.values

df.dtypes

df['Churn'].value_counts().plot(kind='barh', figsize=(8, 6))

df['Churn'].value_counts()

df.info(verbose=True)

missing = pd.DataFrame((df.isnull().sum())*100/df.shape[0]).reset_index()

plt.figure(figsize=(16,5))
ax = sns.pointplot(x='index', y=1, data=missing)
plt.xticks(rotation =90,fontsize =7)
plt.title("Percentage of Missing values")
plt.ylabel("PERCENTAGE")
plt.show()

df.TotalCharges = pd.to_numeric(df.TotalCharges, errors='coerce')
df.isnull().sum()

df.loc[df ['TotalCharges'].isnull() == True]

df.dropna(how = 'any', inplace = True)

print(df['tenure'].max())

labels = ["{0} - {1}".format(i, i + 11) for i in range(1, 72, 12)]

df['tenure_group'] = pd.cut(df.tenure, range(1, 80, 12), right=False, labels=labels)

df['tenure_group'].value_counts()

df.drop(columns= ['customerID','tenure'], axis=1, inplace=True)
df.head()

for i, predictor in enumerate(df.drop(columns=['Churn', 'TotalCharges', 'MonthlyCharges'])):
    plt.figure(i)
    sns.countplot(data=df, x=predictor, hue='Churn')

df['Churn'] = np.where(df.Churn == 'Yes',1,0)

df.head()

pd_dummies = pd.get_dummies(df)
pd_dummies.head()

sns.lmplot(data=pd_dummies, x='MonthlyCharges', y='TotalCharges', fit_reg=False)

Mth = sns.kdeplot(pd_dummies.MonthlyCharges[(pd_dummies["Churn"] == 0) ],
                color="Red", shade = True)
Mth = sns.kdeplot(pd_dummies.MonthlyCharges[(pd_dummies["Churn"] == 1) ],
                ax =Mth, color="Blue", shade= True)
Mth.legend(["No Churn","Churn"],loc='upper right')
Mth.set_ylabel('Density')
Mth.set_xlabel('Monthly Charges')
Mth.set_title('Monthly charges by churn')

plt.figure(figsize=(20,8))
pd_dummies.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')

plt.figure(figsize=(12,12))
sns.heatmap(pd_dummies.corr(), cmap="Paired")

pd_dummies.to_csv('tel_churn.csv')

df=pd.read_csv("tel_churn.csv")
df.head()

x=df.drop('Churn',axis=1)

y=df['Churn']

import pandas as pd
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import recall_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from imblearn.combine import SMOTEENN

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

model_dt=DecisionTreeClassifier(criterion = "gini",random_state = 100,max_depth=6, min_samples_leaf=8)

model_dt.fit(x_train,y_train)

y_pred=model_dt.predict(x_test)
y_pred

model_dt.score(x_test,y_test)

print(classification_report(y_test, y_pred, labels=[0,1]))

sm = SMOTEENN()
X_resampled, y_resampled = sm.fit_resample(x,y)

xr_train,xr_test,yr_train,yr_test=train_test_split(X_resampled, y_resampled,test_size=0.2)

model_dt_smote=DecisionTreeClassifier(criterion = "gini",random_state = 100,max_depth=6, min_samples_leaf=8)

model_dt_smote.fit(xr_train,yr_train)
yr_predict = model_dt_smote.predict(xr_test)
model_score_r = model_dt_smote.score(xr_test, yr_test)
print(model_score_r)
print(metrics.classification_report(yr_test, yr_predict))

print(metrics.confusion_matrix(yr_test, yr_predict))

from sklearn.ensemble import RandomForestClassifier

model_rf=RandomForestClassifier(n_estimators=100, criterion='gini', random_state = 100,max_depth=6, min_samples_leaf=8)

model_rf.fit(x_train,y_train)

y_pred=model_rf.predict(x_test)

model_rf.score(x_test,y_test)

print(classification_report(y_test, y_pred, labels=[0,1]))

model_rf_smote=RandomForestClassifier(n_estimators=100, criterion='gini', random_state = 100,max_depth=6, min_samples_leaf=8)

model_rf_smote.fit(xr_train,yr_train)

yr_predict1 = model_rf_smote.predict(xr_test)

model_score_r1 = model_rf_smote.score(xr_test, yr_test)

print(model_score_r1)
print(metrics.classification_report(yr_test, yr_predict))

print(metrics.confusion_matrix(yr_test, yr_predict))

import pickle

filename = 'model.sav'

pickle.dump(model_rf_smote, open(filename, 'wb'))

load_model = pickle.load(open(filename, 'rb'))

model_score_r1 = load_model.score(xr_test, yr_test)

model_score_r1

